# Tech Challenge - P√≥s-Tech - IA For Devs - FIAP
# Fase 3 - Fine-tuning do modelo DeepSeek

## Alunos:

- Andr√© Mattos - RM358905
- Aurelio Thomasi Jr - RM358104
- Leonardo Ramires - RM358190
- Lucas Arruda - RM358628
- Pedro Marins - RM356883

## Evid√™ncias do projeto

- Link para o reposit√≥rio:
- Link para o v√≠deo de apresenta√ß√£o:
- Link para o modelo treinado: [Deep Seek R1 Products](https://huggingface.co/rickwalking/DeepSeek-R1-Products)
- Link para o dataset: [Amazon Titles Reasoning](https://huggingface.co/datasets/rickwalking/amazon-titles-reasoning)

## Descri√ß√£o

Este projeto tem como objetivo criar um fine-tuning utilizando do foundation model DeepSeek. Para realiza√ß√£o do fine-tuning, foi utilizado um dataset chamado "AmazonTitles-1.3MM" que cont√©m 1.3 milh√£o de t√≠tulos e descri√ß√µes de produtos da Amazon.

Destes 1.3 milh√£o de registros, foi selecionado 2000 registros para um processo de amostragem. Este processo foi realizado para adicionar um contexto que fosse compat√≠vel com o modelo DeepSeek, para realizar o fine-tuning.
Um tratamento foi feito para que os dados fossem compat√≠veis com o modelo DeepSeek e tamb√©m para adicionar um contexto ao trabalho. 

### Contexto

A cria√ß√£o de um assistente virtual de compras √© algo que pode ser muito √∫til para o usu√°rio, pois o mesmo poder√° ajudar em praticamente todas as etapas de uma compra na Amazon. Este assistente virtual dever√° ser capaz de responder perguntas sobre os produtos, fornecer recomenda√ß√µes e at√© tirar d√∫vidas sobre o produto que est√° sendo visto pelo usu√°rio.

Ter dados que cont√©m t√≠tulo e descri√ß√£o s√£o uma √≥tima oportunidade para a cria√ß√£o de um assistente LLM, tamb√©m possibilitando que clientes tirem d√∫vidas sem a necessidade de contatar o atendimento humano.

### Processo de amostragem
![*Figura 1: Processo de amostragem*](images/amostragem.png)

*Figura 1: Processo de amostragem*

O processo de amostragem consiste em selecionar os 2000 (pode ser configurado) registros que ser√£o utilizados para o fine-tuning. Os registros selecionados devem ter as seguintes caracter√≠sticas:

- T√≠tulo n√£o pode ser vazio
- Descri√ß√£o n√£o pode ser vazia

Ap√≥s serem selecionados, os registros foram tratados para se tornarem compat√≠veis com o fine-tuning do modelo DeepSeek. Ent√£o foi utilizado um modelo local(utilizando o Ollama) do DeepSeek para realizar a transforma√ß√£o dos dados para o formato do modelo. O prompt para gera√ß√£o dos dados para cada registro na lista de registros selecionados foi o seguinte:

```
    You are a helpful assistant that generates data for fine-tuning DeepSeek model.
    You will be given a product title and context (description).
    You need to generate a question, reasoning, and answer based on the product title and context.
    The format should be as follows:
    Question: <question>
    Complex_CoT: <reasoning>
    Response: <answer>
    Your response should be a JSON object in the format above, assuming that an user is looking for a product on Amazon.
    Your response to this request should only include the JSON result, no description should be added.
    The question should be a question that an user would ask to find the product on Amazon.
    The reasoning should be a detailed reasoning for the question, with all the steps and the final answer.
    The answer should be the answer to the question.

    Here is the product title and context:
    Title: {json_data['title']}
    Context: {json_data['context']}
```

Como pode ser visto, para cada registro recebido, foi gerado um JSON com o formato de pergunta, complex_cot e resposta. Isto foi poss√≠vel gra√ßas aos seguintes modules de script python:
- `main.py` - Entrypoint do projeto.
- `modules/open_raw_data.py` - Este module √© respons√°vel por abrir o arquivo JSON com os dados brutos. O arquivo AmazonTitles-1.3MM.
- `modules/handle_process_inputs.py` - Este module √© respons√°vel por tratar os dados recebidos e gerar um JSON com o formato de pergunta, complex_cot e resposta.
- `modules/process_product.py` - Este module √© respons√°vel por processar o JSON gerado e retornar JSON com o formato de question, complex_cot e response.
- `modules/deep_seek.py` - Este module √© respons√°vel por chamar o modelo local do DeepSeek e retornar o JSON com o formato de question, complex_cot e response.
- `modules/save_results.py` - Este module √© respons√°vel por salvar todos os registros gerados em um arquivo JSON.

Ap√≥s todo processamento dos dados, o resultado final foi enviado para um reposit√≥rio no [Hugging Face](https://huggingface.co/datasets/rickwalking/amazon-titles-reasoning).

### Dados para treinamento

O modelo DeepSeek possu√≠ um formato de dados pr√≥prio para realizar o fine-tuning, que √© o seguinte:

```
{
    "Question": "Pergunta de um usu√°rio sobre um produto da Amazon",
    "Complex_CoT": "Cadeia de racioc√≠nio complexa para responder a pergunta do usu√°rio. O modelo deve responder a pergunta do usu√°rio de forma completa, utilizando o t√≠tulo e a descri√ß√£o do produto como contexto.",
    "Response": "Resposta final para a pergunta do usu√°rio"
}
```

O dataset de amostragem est√° pronto para ser utilizado para o fine-tuning do modelo DeepSeek.

## Tecnologias

- Python - Linguagem de programa√ß√£o utilizada para a cria√ß√£o do projeto.
- PyTorch - Biblioteca de machine learning utilizada para o fine-tuning do modelo DeepSeek.
- Transformers - Biblioteca de machine learning utilizada para o fine-tuning do modelo DeepSeek.
- Hugging Face - Reposit√≥rio de datasets utilizado para o fine-tuning do modelo DeepSeek.
- AmazonTitles-1.3MM - Dataset utilizado para o fine-tuning do modelo DeepSeek.
- DeepSeek - Modelo de machine learning utilizado para o fine-tuning.
- Ollama - O Ollama √© uma ferramenta que permite rodar modelos LLM localmente.
- Google Colab - Plataforma de notebook utilizada para o fine-tuning do modelo DeepSeek.
- Unsloth - Ferramenta utilizada para o treinamento do modelo DeepSeek
- Wandb - Ferramenta chamada Weights and Biases, que √© uma ferramenta de monitoramento do treinamento do modelo DeepSeek, mostrando estatisticas e g≈ïaficos ap√≥s o treinamento.

### O treinamento do modelo DeepSeek

![Figura 2: Treinamento do modelo DeepSeek](images/training.png)

*Figura 2: Treinamento do modelo DeepSeek*

O treinamento do modelo DeepSeek foi realizado em um notebook do Google Colab, com a utiliza√ß√£o da GPU T4 para que o treinamento fosse mais r√°pido, o resultado foi um treinamento que durou em torno de 34 minutos.
O treinamento foi realizado com o dataset de amostragem, que foi gerado anteriormente pelo script de cria√ß√£o de dados.
A ferramenta Unsloth foi utilizada para realizar o treinamento do modelo, com as seguintes configura√ß√µes:

### Detalhes do Foundation Model

-> **Nome: unsloth/DeepSeek-R1-Distill-Llama-8B**: Modelo base.

**Caracter√≠sticas:**

- Otimizado, 2-5x mais r√°pido que o modelo original, com um custo de mem√≥ria (70%) menor.
- Modelo treinado com reinforcement learning. O que significa que o modelo que tem uma capacidade de autoavalia√ß√£o e autoaprendizado e reasoning.
- Treinamento eficiente com LoRA para que o modelo possa ser adaptado para o fine-tuning.
    
üìå **Fonte:** [Hugging Face Model Card](https://huggingface.co/unsloth/DeepSeek-R1-Distill-Llama-8B)

### Detalhes de configura√ß√µes do fine-tuning

#### Tamanho dos Batches e Gradientes

| Argumento | Descri√ß√£o |
|-----------|------------|
| `per_device_train_batch_size = 2` | Define o n√∫mero de exemplos processados por batch em cada GPU. Um batch pequeno consome menos mem√≥ria, mas pode afetar a estabilidade do treinamento. |
| `gradient_accumulation_steps = 4` | Acumula gradientes por 4 passos antes de atualizar os pesos do modelo. Isso simula um batch maior sem exigir mais mem√≥ria da GPU. |

**Exemplo:** Se `batch_size = 2` e `gradient_accumulation_steps = 4`, o modelo s√≥ atualiza os pesos ap√≥s processar **8 exemplos**.

---

#### Etapas de Treinamento

| Argumento | Descri√ß√£o |
|-----------|------------|
| `warmup_steps = 5` | N√∫mero de passos iniciais onde a taxa de aprendizado cresce gradualmente para evitar varia√ß√µes bruscas no gradiente. |
| `max_steps = 120` | N√∫mero total de passos de treinamento. Neste caso, √© um teste. Para um treinamento real, pode-se definir `num_train_epochs`. |
| `num_train_epochs = 2` | Define quantas √©pocas completas o dataset ser√° percorrido durante o treinamento. |

---

#### Taxa de Aprendizado e Otimiza√ß√£o

| Argumento | Descri√ß√£o |
|-----------|------------|
| `learning_rate = 2e-4` | Define a taxa de aprendizado do otimizador. Valores altos aceleram o aprendizado, mas podem ser inst√°veis. |
| `weight_decay = 0.01` | Regulariza√ß√£o L2 para evitar overfitting, penalizando pesos muito grandes. |
| `lr_scheduler_type = "linear"` | Define o decaimento da taxa de aprendizado. O tipo `linear` reduz a taxa gradualmente at√© o final do treinamento. |

---

#### Precis√£o e Performance

| Argumento | Descri√ß√£o |
|-----------|------------|
| `fp16 = not is_bfloat16_supported()` | Usa **FP16** (16-bit floating point) se `bfloat16` n√£o estiver dispon√≠vel. FP16 economiza mem√≥ria, mas pode ser inst√°vel. |
| `bf16 = is_bfloat16_supported()` | Usa **bfloat16** se a GPU suportar. BF16 √© mais est√°vel que FP16, consumindo a mesma quantidade de mem√≥ria. |
| `optim = "adamw_8bit"` | Usa o otimizador **AdamW** em 8 bits, reduzindo o uso de mem√≥ria do otimizador sem perder efici√™ncia. |

---

#### Logging e Salvamento

| Argumento | Descri√ß√£o |
|-----------|------------|
| `logging_steps = 10` | Define a frequ√™ncia com que m√©tricas como **loss** s√£o registradas. Valores menores geram logs mais frequentes. |
| `output_dir = "outputs"` | Define o diret√≥rio onde os logs e checkpoints do modelo ser√£o salvos. |

---

#### Reprodutibilidade

| Argumento | Descri√ß√£o |
|-----------|------------|
| `seed = 3407` | Define uma semente fixa para garantir que os experimentos sejam reproduz√≠veis. Isso significa que, ao rodar o treinamento novamente, os resultados ser√£o os mesmos. |

---

#### SFTTrainer

O `SFTTrainer` (Supervised Fine-Tuning Trainer) √© uma classe especializada para **fine-tuning eficiente** usando LoRA. Ele recebe os argumentos definidos acima (`args = training_arguments`) e adiciona configura√ß√µes espec√≠ficas.

#### Configura√ß√µes B√°sicas

| Argumento | Descri√ß√£o |
|-----------|------------|
| `model = deep_seek_model` | O modelo que ser√° treinado. Neste caso, um modelo **DeepSeek com LoRA**. |
| `tokenizer = tokenizer` | O tokenizador usado para processar os textos antes do treinamento. |
| `train_dataset = amazon_titles_reasoning formatado` | O dataset formatado no padr√£o necess√°rio para o treinamento. |
| `dataset_text_field = "text"` | Define qual campo do dataset cont√©m o texto a ser usado no treinamento. |

---

#### Tamanho da Sequ√™ncia e Processamento

| Argumento | Descri√ß√£o |
|-----------|------------|
| `max_seq_length = 2048` | Define o tamanho m√°ximo de tokens que o modelo pode processar em uma √∫nica entrada. |
| `dataset_num_proc = 2` | N√∫mero de processos paralelos para pr√©-processamento do dataset. Valores maiores podem acelerar, mas exigem mais CPU. |

---

#### Explica√ß√£o dos Par√¢metros de Gera√ß√£o de Texto

A fun√ß√£o `.generate()` do modelo ajustado (`deep_seek_model`) √© respons√°vel por gerar texto com base em um input processado. Cada argumento influencia diretamente **a forma como o modelo gera texto**, afetando **comprimento, aleatoriedade e efici√™ncia**.

```python
outputs = deep_seek_model.generate(
    **inputs,
    max_new_tokens = 1200,  # M√°ximo de tokens na resposta
    temperature    = 0.2,  # Controla aleatoriedade (0.0 a 1.0)
    use_cache      = True  # Ativa cache para melhorar a velocidade de gera√ß√£o
)
```

| Par√¢metro | O que faz? | Valores recomendados |
|-----------|-----------|---------------------|
| **`max_new_tokens`** | Define **o n√∫mero m√°ximo de novos tokens** que podem ser gerados **na resposta** | `50-200` (depende do contexto) |
| **`temperature`** | Controla o n√≠vel de **aleatoriedade** da gera√ß√£o de texto | `0.3` (formal) - `0.8` (criativo) |
| **`use_cache`** | Usa cache para **acelerar gera√ß√£o** | Sempre `True` |

**Exemplo "max_new_tokens":** Se `max_new_tokens = 1200`, o modelo pode **gerar at√© 1200 tokens** depois do prompt de entrada.
  - Um valor muito **baixo** pode truncar a resposta antes que ela seja conclu√≠da.
  - Um valor muito **alto** pode gerar respostas longas e desnecess√°rias, consumindo mais mem√≥ria e tempo de infer√™ncia

**Exemplo "temperature":** A temperatura recomendada pelo reposit√≥rio do Foundation Model √© `0.7`. Foram realizados testes com valores menores (0.2) e o modelo gerou respostas mais diretas e objetivas. N√£o houve problemas como foi mencionado no card do modelo.

**Exemplo "use_cache":** Ativa um **cache interno** para acelerar a gera√ß√£o de tokens.
  - Durante a gera√ß√£o, o modelo precisa **calcular os tokens anteriores repetidamente**.
  - Com **`use_cache = True`**, ele **armazena os tokens j√° processados**, evitando recomputa√ß√£o desnecess√°ria.

#### LoRA

A aplica√ß√£o do LoRA foi realizada para o treinamento do fine-tuning. Permitindo um ganho de performance e redu√ß√£o de custo e tempo de treinamento. O LoRA realiza uma adapta√ß√£o din√¢mica dos pesos do modelo, adotando uma abordagem de treinamento de camadas espec√≠ficas.
Em outras palavras, √© como se o LLM fosse uma f√°brica complexa, onde o LoRA permite reconstruir partes da f√°brica e consiga fabricar um novo produto, sem ter que reconstruir toda a f√°brica. Esta nova parte da f√°brica ser√° respons√°vel por fabricar o novo produto, neste caso, √© o contexto adicional que foi inclu√≠do durante o fine-tuning, com o intuito de melhorar a resposta do modelo para o usu√°rio que est√° com d√∫vidas sobre algum produto.

### Resultado do treinamento do modelo (Training Loss)

![Figura 3: Training Loss](images/training_loss.png)

*Figura 3: Training Loss*

O comportamento o training loss √© o seguinte:

- In√≠cio: Queda acentuada de 2.15 para 0.96 (primeiros 20 steps)
- Meio: Estabiliza√ß√£o entre 0.8-0.9 (steps 30-120)
- Final: Redu√ß√£o gradual at√© 0.68 (steps 120-270)

O treinamento demonstrou excelente converg√™ncia, reduzindo o loss consideravelmente. A estabilidade dos valores finais e a aus√™ncia de overfitting indicam que o modelo est√° bem adaptado para atuar como assistente virtual de compras da Amazon, validando a efic√°cia da abordagem LoRA utilizada.

para mais detalhes sobre o treinamento, acesse as estatisticas [aqui](https://wandb.ai/rickwalking1272-n-a/huggingface/runs/443an42a?nw=nwuserrickwalking1272).

### Compara√ß√£o de respostas (Antes do fine-tuning e ap√≥s o fine-tuning)

Abaixo est√£o as respostas geradas pelo modelo antes do fine-tuning e ap√≥s o fine-tuning, com o aux√≠lio da ferramenta Wandb (Weights and Biases).

#### Antes do fine-tuning

Foi utilizado um promp sobreo contexto de um produto da Amazon. O modelo neste momento n√£o possu√≠ nenhum contexto adicional para responder a pergunta. Ent√£o, o modelo deve responder de forma gen√©rica.

```
Is 'Worship with Don Moen' available on VHS?
```

E o reasoning foi o seguinte:

```
Okay, so I need to figure out if "Worship with Don Moen" is available on VHS. First, I should consider what VHS is. VHS, or Video Home System, was a popular format for video cassettes before DVD and Blu-ray. Many older movies and videos were released on VHS, but with the rise of digital formats, VHS has become less common.

Now, the question is about a specific product: "Worship with Don Moen." I don't recognize this title immediately, so I should think about what it might be. "Worship" suggests it's related to religious or spiritual content, possibly a video or a series of videos featuring Don Moen, who might be a musician, speaker, or religious leader.

I need to determine if such a product exists on VHS. Since VHS is a physical medium, I should check sources where VHS tapes are sold. Online marketplaces like eBay often have listings for VHS tapes. I can search there using the title "Worship with Don Moen" to see if any listings come up.

Alternatively, I can check if the product is available on other platforms like Amazon. However, since the question is specifically about VHS, I should focus on that. If I search eBay, I can filter the search to show only VHS listings. If there are results, that means the product is available on VHS. If not, it might not be available in that format anymore.

I should also consider the likelihood of the product being available. Don Moen might have released this on other formats like DVD or Blu-ray, which are more common now. The availability on VHS depends on the demand and how popular the product is. If it's a niche or older product, it might still be available on VHS, but if it's more recent, it's probably only on newer formats.

In summary, to determine if "Worship with Don Moen" is available on VHS, I should check online marketplaces where VHS tapes are sold, such as eBay, and search for the title there. If listings are found, the answer is yes; if not, it might not be available on VHS anymore.
```

E a resposta foi a seguinte:

```
Worship with Don Moen" is not available on VHS. While it may be available on other formats like DVD or Blu-ray, VHS listings for this product are no longer common, indicating that it is likely only accessible through newer digital formats
```

#### Ap√≥s o fine-tuning

Ap√≥s o fine-tuning, foi utilizado o mesmo prompt anterior, mas agora com o contexto adicional que foi adicionado durante o fine-tuning, √© esperado que o modelo responda de forma mais assertiva e coerente, com objetivo de ajudar o usu√°rio a encontrar o produto que o cliente est√° procurando.

```
Is 'Worship with Don Moen' available on VHS??
```

O reasoning foi o seguinte:

```
The product title is 'Worship with Don Moen,' and the context mentions that it is a VHS tape. Therefore, the answer would be yes.
```

A resposta foi a seguinte:

```
Yes
```

No notebook do fine-tuning, √© poss√≠vel encontrar perguntas e respostas adicionais de acordo com o contexto fornecido. Mostrando que o modelo agora √© capaz de responder de forma objetiva a perguntas de usu√°rios sobre diferentes produtos da Amazon.

### Conclus√£o

O fine-tuning do modelo DeepSeek foi um sucesso, com uma redu√ß√£o grande no loss e uma melhoria significativa nas respostas geradas. O modelo agora √© capaz de gerar respostas mais precisas e coerentes, validando a efic√°cia da abordagem LoRA utilizada. Este modelo agora pode atuar como um assistente virtual de compras da Amazon, com uma capacidade de respostas mais assertivas com o contexto fornecido.
