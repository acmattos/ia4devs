# üéì Tech Challenge - P√≥s-Tech - IA For Devs - FIAP
# üìπ Fase 4 - An√°lise de v√≠deo com IA

## üë• 1. Alunos:

- Andr√© Mattos - RM358905
- Aurelio Thomasi Jr - RM358104
- Leonardo Ramires - RM358190
- Lucas Arruda - RM358628
- Pedro Marins - RM356883

## üìã 2. Evid√™ncias do projeto

- Link para o reposit√≥rio:[Repositorio Git](https://github.com/acmattos/ia4devs/tree/main/module_04/04_Tech_Challenge)
- Link para o v√≠deo de apresenta√ß√£o: [Video Apresenta√ß√£o]

## üìö 3. Bibliotecas utilizadas

- Principais bibliotecas:
  - **OpenCV (cv2)**: Biblioteca utilizada para processamento de v√≠deo, detec√ß√£o de rostos e manipula√ß√£o de imagens.
  - **DeepFace**: Biblioteca utilizada para an√°lise de emo√ß√µes faciais (feliz, triste, etc).
  - **MediaPipe**: Biblioteca utilizada para detec√ß√£o de movimentos(pose corporal, movimentos das m√£os, etc).
  - **ultralytics**: Biblioteca alternativa que foi utilizada para detectar faces e classificar emo√ß√µes, utilizando o modelo Yolo11.
  
- Bibliotecas de suporte:
  - **Dlib**: Biblioteca base para o face_recognition, utilizada para detec√ß√£o e codifica√ß√£o de rostos.
  - **Tensorflow**: Depend√™ncia do DeepFace para an√°lise de emo√ß√µes.
  - **Pandas**: Biblioteca utilizada para gera√ß√£o de relat√≥rios e an√°lise dos dados coletados.
  - **NumPy**: Biblioteca utilizada para opera√ß√µes matem√°ticas e manipula√ß√£o de arrays.
  - **tqdm**: Biblioteca utilizada para exibir barras de progresso durante o processamento do v√≠deo que est√° sendo analisado.
  - **Vosk**: Modelo utilizada para transcri√ß√£o de √°udio do v√≠deo para texto [Vosk Model](https://alphacephei.com/vosk/models).
  - **Yolo**: Modelo utilizado pelo ultralytics na dete√ß√£o de emo√ß√µes: [yolov11l-face.pt](https://github.com/akanametov/yolo-face/releases/download/v0.0.0/yolov11l-face.pt).

## üíª 4. Instalar Dlib e Tensorflow (Windows)

Durante o desenvolvimento do projeto, foi necess√°rio instalar o Dlib e o 
Tensorflow para a utiliza√ß√£o de CUDA, para processar os v√≠deos com GPU e 
consequentemente melhorar o desempenho do processamento.
No final desta documenta√ß√£o, ser√° apresentado o passo a passo para instalar o 
Dlib e o Tensorflow para o ambiente Windows (ambiente de desenvolvimento utilizado).

**CUDA**: √â uma biblioteca de software utilizada em hardware de computa√ß√£o 
gr√°fica da empresa NVIDIA, que permite a utiliza√ß√£o de GPUs para acelerar o 
processamento de c√°lculos matem√°ticos (Por exemplo, matrizes, c√°lculos de IA, etc).

## üìù 6. Descri√ß√£o

Este Tech Challenge tem como objetivo de criar uma aplica√ß√£o que utilize an√°lise 
de v√≠deo com IA, para detectar os seguintes eventos:
- Reconhecimento facial: Identificar e marcar pessoas no v√≠deo.
- An√°lise de express√µes emocionais: Identificar e analise express√µes dos rostos identificados.
- Detec√ß√£o de atividades: Detectar e categorizar atividades sendo realizadas no v√≠deo.
- Gera√ß√£o de resumo: Um resumo autom√°tico das principais atividades e emo√ß√µes detectadas no v√≠deo.

Ap√≥s as detec√ß√µes, os sistema ir√° gerar automaticamente um relat√≥rio com as 
principais atividades e emo√ß√µes detectadas no v√≠deo.
O relat√≥rio deve incluir:
- Total de frames analisados
- N√∫mero de anomalias detectadas

## üë§ 7. Detec√ß√£o de rostos - reconhecimento facial

Esta parte do projeto foi desenvolvida utilizando a bibliotca **OpenCV** para 
realizar o processamento.
Os seguintes passos s√£o realizados neste processo:

1. Carregar o modelo de detec√ß√£o de rostos.
2. Carregar o v√≠deo.
3. Processar o v√≠deo frame a frame.
4. Detectar rostos no frame.
5. Desenhar ret√¢ngulos ao redor dos rostos detectados.
6. Identificar nome de pessoas de acordo com imagens de refer√™ncia que est√£o salvas no diret√≥rio `images`.
7. Salvar o frame com os ret√¢ngulos desenhados.
8. Atualizar o relat√≥rio com os dados coletados.

### 7.1 Imagens de refer√™ncia

As imagens de refer√™ncia foram salvas no diret√≥rio `images` e foram utilizadas 
para identificar as pessoas no v√≠deo.
As seguintes imagens foram utilizadas:

- **Ann** (01Ann_A01.png)
- **Brunna** (01Brunna_B01.png)
- **Charles** (01Charles_C01.png)
- **Danielle** (01Danielle_D01.png)
- **Ed** (02Ed_E01.png)
- **Faith** (04Faith_F01.png)
- **Garth** (05Garth_G01.png)
- **Harry** (06Harry_H01.png)
- **Ivy** (07Ivy_I01.png)
- **John** (08John_J01.png)
- **Kay** (12Kay_K01.png)
- **Lana** (13Lana_L01.png)
- **Mark** (14Mark_M01.png)
- **Noah** (15Noah_N01.png)
- **Oswald** (17Oswald_O01.png)
- **Paula** (17Paula_P01.png)
- **Rita** (17Rita_R01.png)
- **Saul** (17Saul_S01.png)
- **Thor** (18Thor_T01.png)

### 7.2 Processamento do v√≠deo e par√¢metros

A fun√ß√£o `face_detection_and_recognition` √© respons√°vel por realizar o 
reconhecimento facial no v√≠deo. O processo consiste em:

1. **Carregamento de Dados**:
   - Carrega as imagens de refer√™ncia do diret√≥rio especificado.
   - Inicializa o v√≠deo de entrada e cria o arquivo de sa√≠da.
   - Prepara as estruturas de dados para armazenar os resultados.

2. **Processamento Frame a Frame**:
   - Para cada frame do v√≠deo:
     - Converte o frame para RGB (necess√°rio para o `face_recognition`).
     - Detecta rostos e gera codifica√ß√µes faciais.
     - Compara com as imagens de refer√™ncia.
     - Desenha ret√¢ngulos e nomes ao redor dos rostos identificados.
     - Salva os resultados para an√°lise posterior.

3. **Gera√ß√£o de Relat√≥rio**:
   - Cria um arquivo CSV com os resultados.
   - Gera um resumo da an√°lise com estat√≠sticas.

4. **Anomalias**:
   - Se o nome da pessoa n√£o for encontrado nas imagens de refer√™ncia, o sistema 
     ir√° marcar a pessoa como "An√¥nimo".

#### 7.2.1 Par√¢metros da Fun√ß√£o

| Par√¢metro | Tipo | Descri√ß√£o |
|-----------|------|-----------|
| `images_path` | str | Caminho para o diret√≥rio contendo as imagens de refer√™ncia |
| `video_in_path` | str | Caminho do arquivo de v√≠deo de entrada |
| `video_out_path` | str | Caminho onde ser√° salvo o v√≠deo processado |

#### 7.2.2 Par√¢metros Internos

| Par√¢metro | Valor Padr√£o | Descri√ß√£o |
|-----------|--------------|-----------|
| `number_of_times_to_upsample` | 5 | N√∫mero de vezes que a imagem √© redimensionada para detectar rostos menores |
| `model` | "cnn" | Modelo de detec√ß√£o facial ("cnn" para GPU, "hog" para CPU) |
| `num_jitters` | 40 | N√∫mero de amostragens para gerar a codifica√ß√£o facial |
| `encoding_model` | "large" | Modelo de codifica√ß√£o facial ("large" para 128 pontos, "small" para 5 pontos) |

#### 7.2.3 Sa√≠das

1. **V√≠deo Processado**:
   - Arquivo MP4 com os rostos identificados.
   - Ret√¢ngulos coloridos ao redor dos rostos.
   - Nomes das pessoas identificadas.

2. **Arquivo CSV**:
   - Frame ID.
   - Nome da pessoa identificada.
   - Timestamp do frame.

3. **Resumo da An√°lise**:
   - Total de frames processados.
   - Estat√≠sticas de detec√ß√£o por pessoa.
   - Tempo total de processamento.

## üòä 8. Detec√ß√£o de emo√ß√µes - express√µes faciais

Esta parte do projeto foi desenvolvida utilizando a biblioteca **DeepFace** para 
realizar a an√°lise de emo√ß√µes. O processo consiste em:

1. **Carregamento de Dados**:
   - Inicializa o v√≠deo de entrada.
   - Prepara o arquivo de sa√≠da para o v√≠deo processado.
   - Configura as estruturas de dados para armazenar os resultados.

2. **Processamento Frame a Frame**:
   - Para cada frame do v√≠deo:
     - Detecta rostos usando OpenCV (DNN ou Haar Cascade).
     - Analisa as emo√ß√µes de cada rosto detectado usando DeepFace e escreve o nome da emo√ß√£o que foi detectada.
     - Desenha ret√¢ngulos ao redor dos rostos identificados.
     - Salva os resultados para an√°lise posterior.

3. **Gera√ß√£o de Relat√≥rio**:
   - Cria um arquivo CSV com os resultados
   - Gera um resumo da an√°lise com estat√≠sticas de emo√ß√µes

#### 8.1 Par√¢metros da Fun√ß√£o

| Par√¢metro | Tipo | Descri√ß√£o |
|-----------|------|-----------|
| `video_in_path` | str | Caminho do arquivo de v√≠deo de entrada |
| `video_out_path` | str | Caminho onde ser√° salvo o v√≠deo processado |

#### 8.2 Par√¢metros Internos

| Par√¢metro | Valor Padr√£o | Descri√ß√£o |
|-----------|--------------|-----------|
| `actions` | ['emotion'] | Lista de a√ß√µes a serem analisadas pelo DeepFace |
| `detector_backend` | 'centerface' | Backend de detec√ß√£o facial ('opencv', 'mtcnn', 'skip', 'mediapipe' ou 'centerface') |
| `enforce_detection` | False | Se deve for√ßar a detec√ß√£o mesmo com baixa confian√ßa |
| `anti_spoofing` | False | Se deve verificar se o rosto √© real ou uma foto |

#### 8.3 Emo√ß√µes Detectadas

O sistema √© capaz de detectar as seguintes emo√ß√µes:
- **Feliz** (happy)
- **Triste** (sad)
- **Neutro** (neutral)
- **Surpreso** (surprise)
- **Com medo** (fear)
- **Irritado** (angry)
- **Desconhecido** (unknown) - quando n√£o √© poss√≠vel detectar a emo√ß√£o

#### 8.4 Sa√≠das

1. **V√≠deo Processado**:
   - Arquivo MP4 com os rostos e emo√ß√µes identificados.
   - Ret√¢ngulos coloridos ao redor dos rostos.
   - Emo√ß√£o detectada para cada rosto.

2. **Arquivo CSV**:
   - Frame ID.
   - Emo√ß√µes detectadas (at√© 4 emo√ß√µes por frame).
   - Timestamp do frame.

3. **Resumo da An√°lise**:
   - Total de frames processados.
   - Estat√≠sticas de cada emo√ß√£o detectada.
   - Tempo total de processamento.

## üéôÔ∏è 9. Transcri√ß√£o do v√≠deo

Esta parte do projeto foi desenvolvida utilizando as bibliotecas **MoviePy** e 
**Vosk** para realizar a transcri√ß√£o do √°udio do v√≠deo. Isso n√£o √© um requisito p
ara o projeto, mas foi uma op√ß√£o considerada para o desenvolvimento porque √© uma 
an√°lise √∫til e faz parte da fase atual da Pos-Tech. O processo consiste em:

1. **Extra√ß√£o do √Åudio**:
   - Carrega o arquivo de v√≠deo usando MoviePy.
   - Extrai a faixa de √°udio do v√≠deo.
   - Salva o √°udio em formato WAV com qualidade CD (44.1kHz, 16-bit, mono).

2. **Processamento do √Åudio**:
   - Carrega o arquivo de √°udio extra√≠do.
   - Converte o √°udio para o formato adequado para reconhecimento de fala.
   - Utiliza o modelo Vosk para transcri√ß√£o offline.

3. **Gera√ß√£o da Transcri√ß√£o**:
   - Realiza o reconhecimento de fala.
   - Salva o texto transcrito em um arquivo.
   - Exibe o progresso durante o salvamento.

#### 9.1 Par√¢metros da Fun√ß√£o

| Par√¢metro | Tipo | Descri√ß√£o |
|-----------|------|-----------|
| `video_in_path` | str | Caminho do arquivo de v√≠deo de entrada |
| `audio_out_path` | str | Caminho onde ser√° salvo o arquivo de √°udio extra√≠do |
| `text_out_path` | str | Caminho onde ser√° salva a transcri√ß√£o em texto |

#### 9.2 Par√¢metros Internos

| Par√¢metro | Valor Padr√£o | Descri√ß√£o |
|-----------|--------------|-----------|
| `fps` | 44100 | Taxa de amostragem do √°udio (Hz) |
| `nbytes` | 2 | Profundidade de bits (2 = 16-bit) |
| `codec` | 'pcm_s16le' | Codec de √°udio (WAV 16-bit) |
| `ffmpeg_params` | ["-ac", "1"] | Par√¢metros para for√ßar sa√≠da mono |

#### 9.3 Requisitos

1. **Modelo Vosk**:
   - √â necess√°rio baixar e instalar o modelo de linguagem Vosk.

2. **Depend√™ncias**:
   - **MoviePy**: Biblioteca utilizada para manipula√ß√£o de v√≠deo e √°udio.
   - **SpeechRecognition**: Biblioteca utilizada para interface com o Vosk.
   - **FFmpeg**: Biblioteca utilizada para processamento de √°udio.

#### 9.4 Sa√≠das

1. **Arquivo de √Åudio**:
   - Formato WAV
   - Qualidade CD (44.1kHz)
   - √Åudio mono
   - 16-bit de profundidade

2. **Arquivo de Transcri√ß√£o**:
   - Formato texto (.txt)
   - Codifica√ß√£o UTF-8
   - Texto transcrito do √°udio
   - Salvo em chunks para melhor performance

3. **Feedback**:
   - Barra de progresso durante o processamento
   - Mensagens de status no console
   - Transcri√ß√£o exibida no terminal

## üìä 10. Modelo YOLO

Esta se√ß√£o tem como objetivo apresentar uma solu√ß√£o alternativa para a detec√ß√£o
de faces e classifica√ß√£o de emo√ß√µes, utilizando o modelo YOLO.

O modelo YOLO (You Only Look Once) √© um modelo que √© capaz de detectar
objetos em tempo real. Ele √© capaz de detectar faces e classificar emo√ß√µes com uma precis√£o muito alta.
Este modelo foi utilizado para comparar com a solu√ß√£o atual utilizada no projeto,
com intuito de validar solu√ß√µes alternativas que podem ser mais eficientes para o problema proposto.

### üë§ 10.1 Detec√ß√£o de faces

A detec√ß√£o de faces foi realizada utilizando o modelo YOLO11, que traz melhorias de desempenho,
precis√£o, flexibilidade e efici√™ncia em Vis√£o Computacional.
O processo de detec√ß√£o de faces foi realizado no arquivo `recognize_expression_yolo.py`.

#### üîÑ Passos da Implementa√ß√£o:

1. **Carregamento e Configura√ß√£o do Modelo**:
   - Utiliza o modelo YOLOv11 especificamente treinado para detec√ß√£o de faces (`yolov11l-face.pt`)
   - O modelo √© carregado do diret√≥rio `./doc/model`

2. **Processo de Detec√ß√£o Facial** (fun√ß√£o `detectar_pessoas`):
   - Recebe um frame e o processa usando o modelo YOLO
   - Para cada face detectada:
     - Extrai as coordenadas da face (x1, y1, x2, y2)
     - Desenha ret√¢ngulos ao redor dos rostos detectados

3. **An√°lise de Emo√ß√µes** (fun√ß√£o `analisar_emocao`):
   - Utiliza DeepFace em conjunto com YOLO
   - Redimensiona as faces detectadas para `224x224 pixels`
   - Analisa emo√ß√µes usando `MTCNN` como backend de detec√ß√£o (est√° hardcoded no c√≥digo)
   - Retorna a emo√ß√£o dominante para cada face

4. **Processamento de V√≠deo** (fun√ß√£o `processar_video`):
   - Processa o v√≠deo frame a frame com o seguinte fluxo:
     - L√™ as propriedades do v√≠deo (largura, altura, fps, total de frames)
     - Cria um escritor de v√≠deo de sa√≠da com codec `MP4`
     - Processa a cada `5 frames` para detec√ß√£o facial e an√°lise de emo√ß√µes
     - Utiliza processamento paralelo para an√°lise de emo√ß√µes
     - Desenha ret√¢ngulos ao redor das faces detectadas e adiciona texto com a emo√ß√£o detectada nos frames
     - Salva os frames processados no v√≠deo de sa√≠da

5. **Processamento de Resultados**:
   - Salva resultados em arquivo CSV com colunas:
     - frame_id
     - emotions_1 at√© emotions_4 (at√© 4 emo√ß√µes por frame)
   - Gera an√°lise resumida em `summary_analysis.txt`
   - **Restaura √°udio do v√≠deo original para o v√≠deo de sa√≠da**

#### üìä Resultados Esperados:

1. **Sa√≠da Visual**:
   - Um arquivo de v√≠deo processado (`tc4_video_fe_yolo.mp4`) contendo:
     - Ret√¢ngulos ao redor das faces detectadas
     - Texto com a emo√ß√£o detectada para cada face
     - √Åudio original preservado do v√≠deo de entrada

2. **Sa√≠da de Dados**:
   - Arquivo CSV (`tc4_video_fe_yolo.mp4.csv`) contendo:
     - Resultados de detec√ß√£o de emo√ß√µes frame a frame
     - At√© 4 emo√ß√µes por frame
     - Timestamps para cada detec√ß√£o

3. **Resumo da An√°lise**:
   - Arquivo de resumo (`summary_analysis.txt`) com:
     - Total de apari√ß√µes de cada emo√ß√£o
     - An√°lise de segmentos de emo√ß√£o (m√≠nimo 5 frames)
     - Limiar de pausa de 10 frames entre emo√ß√µes

#### ‚ö° Caracter√≠sticas Principais:

1. **Otimiza√ß√µes de Desempenho**:
   - Processa a cada `5 frames` para reduzir carga computacional
   - Utiliza processamento paralelo para an√°lise de emo√ß√µes
   - Reutiliza resultados de detec√ß√£o facial entre frames

2. **Detec√ß√£o de Emo√ß√µes**:
   - Combina a eficiente detec√ß√£o facial do YOLO com a an√°lise de emo√ß√µes do DeepFace
   - Pode detectar m√∫ltiplas emo√ß√µes por frame
   - Lida de maneira inteligente com casos onde a detec√ß√£o de emo√ß√£o falha

Esta implementa√ß√£o fornece uma solu√ß√£o robusta para detec√ß√£o facial e de emo√ß√µes,
aproveitando as capacidades eficientes de detec√ß√£o facial do YOLO enquanto utiliza
o DeepFace para an√°lise detalhada de emo√ß√µes. O sistema foi projetado para ser 
tanto eficiente (atrav√©s de pulo de frames e processamento paralelo) quanto abrangente 
em sua an√°lise de express√µes faciais em conte√∫do de v√≠deo.

### ‚öñÔ∏è 10.2 Compara√ß√£o entre YOLO e a solu√ß√£o atual

Abaixo est√° uma tabela comparativa entre a solu√ß√£o atual e a solu√ß√£o utilizando o modelo YOLO.

| Caracter√≠stica | Solu√ß√£o Atual | Solu√ß√£o YOLO |
|----------------|---------------|--------------|
| **Detec√ß√£o de Faces** | Usa OpenCV com DNN | Usa YOLOv11 especializado |
| **Precis√£o de Detec√ß√£o** | M√©dia | Alta (modelo especializado em faces) |
| **Velocidade de Processamento** | Processa todos os frames | Processa a cada 5 frames (mais eficiente) |
| **Detec√ß√£o de Emo√ß√µes** | DeepFace direto | YOLO + DeepFace em paralelo |
| **Quantidade de Emo√ß√µes Detectadas** | 75 detec√ß√µes totais | 154 detec√ß√µes totais |
| **Processamento Paralelo** | N√£o implementado | Implementado para an√°lise de emo√ß√µes |
| **Uso de GPU** | Limitado | Otimizado para GPU |
| **Consumo de Mem√≥ria** | Alto | Moderado (devido ao processamento em lotes) |
| **Flexibilidade** | Modelo fixo | Diferentes tamanhos de modelo dispon√≠veis (n, s, m, l, x) |

**Observa√ß√µes:**
- A solu√ß√£o YOLO detectou mais de **2x** emo√ß√µes em compara√ß√£o com a solu√ß√£o atual
- O processamento paralelo na solu√ß√£o YOLO permite an√°lise mais r√°pida
- A solu√ß√£o YOLO √© mais eficiente em termos de recursos computacionais
- A precis√£o da detec√ß√£o facial √© superior na solu√ß√£o YOLO devido ao modelo especializado
- O YOLO consegue detectar mais faces, em condi√ß√µes de baixa luminosidade e tamb√©m quando o rosto est√° parcialmente bloqueado ou com rosto inclinado.
